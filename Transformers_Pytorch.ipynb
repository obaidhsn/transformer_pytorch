{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itbMKQCH-D-8",
        "outputId": "fcac9a8b-ee55-4ad2-82e5-c0f4cc157957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 6])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:x.size(0), :]\n",
        "\n",
        "class ComplexTransformerModel(nn.Module):\n",
        "    def __init__(self, input_size=128, num_classes=6, d_model=128, nhead=8, num_encoder_layers=6, dim_feedforward=512, dropout=0.1, max_len=73):\n",
        "        super(ComplexTransformerModel, self).__init__()\n",
        "\n",
        "        # Embedding layer to project input to model dimension (d_model)\n",
        "        self.embedding = nn.Linear(input_size, d_model)\n",
        "\n",
        "        # Positional Encoding\n",
        "        self.pos_encoder = PositionalEncoding(d_model, max_len)\n",
        "\n",
        "        # Transformer Encoder\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_encoder_layers)\n",
        "\n",
        "        # Classification Head (Linear Layer)\n",
        "        self.fc = nn.Linear(d_model, num_classes)\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, input_size, seq_length) -> (batch_size, seq_length, input_size)\n",
        "        x = x.transpose(1, 2)  # Reshape to (batch_size, seq_length, input_size)\n",
        "        # print(f\"Input shape after transpose: {x.shape}\")\n",
        "\n",
        "        # Embedding\n",
        "        x = self.embedding(x)  # (batch_size, seq_length, d_model)\n",
        "        # print(f\"Shape after embedding: {x.shape}\")\n",
        "\n",
        "        # Transpose for transformer input: (seq_length, batch_size, d_model)\n",
        "        x = x.transpose(0, 1)  # (seq_length, batch_size, d_model)\n",
        "        # print(f\"Shape after transpose for transformer: {x.shape}\")\n",
        "\n",
        "        # Add positional encoding\n",
        "        x = self.pos_encoder(x)\n",
        "\n",
        "        # Transformer Encoder\n",
        "        x = self.transformer_encoder(x)  # (seq_length, batch_size, d_model)\n",
        "\n",
        "        # Pooling: Taking the mean of the sequence output\n",
        "        x = x.mean(dim=0)  # (batch_size, d_model)\n",
        "\n",
        "        # Apply Dropout and Classification layer\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)  # (batch_size, num_classes)\n",
        "\n",
        "        # Return log-softmax for better numerical stability in classification\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    model = ComplexTransformerModel(input_size=128, num_classes=6, max_len=73)\n",
        "    example_input = torch.randn(32, 128, 73)  # Batch size of 32, 128 mel bins, 73 time steps\n",
        "    output = model(example_input)\n",
        "    print(output.shape)  # Expected: torch.Size([32, 6])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load train and text csv files"
      ],
      "metadata": {
        "id": "-Ys_w6zN_8Ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load train and test CSV files\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/Crema/train.csv', sep=\"\\t\")\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Crema/test.csv', sep=\"\\t\")\n",
        "\n",
        "# Check data\n",
        "print(train_df.head())  # Should show filepath and label columns\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBOEyRfm_qDA",
        "outputId": "367337a4-5857-455e-9bee-a2f612436433"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              name                                               path  emotion\n",
            "0  1061_TSI_ANG_XX  /content/drive/MyDrive/Crema/angry/1061_TSI_AN...    angry\n",
            "1  1055_ITS_FEA_XX  /content/drive/MyDrive/Crema/fear/1055_ITS_FEA...     fear\n",
            "2  1037_ITH_SAD_XX  /content/drive/MyDrive/Crema/sadness/1037_ITH_...  sadness\n",
            "3  1039_TAI_HAP_XX  /content/drive/MyDrive/Crema/happy/1039_TAI_HA...    happy\n",
            "4  1040_IEO_DIS_LO  /content/drive/MyDrive/Crema/disgust/1040_IEO_...  disgust\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate Mel Spectograms"
      ],
      "metadata": {
        "id": "afVIf-as_2qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def generate_mel_spectrogram(file_path, n_mels=128, fixed_length=73):\n",
        "    # Load audio file (sr=None keeps original sampling rate)\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "    # Generate mel spectrogram with n_mels\n",
        "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
        "\n",
        "    # Convert to log scale (dB)\n",
        "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "    # Check the time dimension (number of frames)\n",
        "    time_steps = mel_spec_db.shape[1]\n",
        "\n",
        "    # If too short, pad with zeros; if too long, truncate\n",
        "    if time_steps < fixed_length:\n",
        "        pad_width = fixed_length - time_steps\n",
        "        mel_spec_db = np.pad(mel_spec_db, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "    elif time_steps > fixed_length:\n",
        "        mel_spec_db = mel_spec_db[:, :fixed_length]\n",
        "\n",
        "    return mel_spec_db\n",
        "\n",
        "# Example usage\n",
        "file_path = train_df['path'].iloc[0]  # First file\n",
        "mel_spectrogram = generate_mel_spectrogram(file_path)\n",
        "print(mel_spectrogram.shape)  # Output shape will be (128, 73)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmmku6By_6Md",
        "outputId": "7743fba9-d530-4817-b63a-88efc990b7e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 73)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create PyTorch Dataset"
      ],
      "metadata": {
        "id": "_E1yIOpWA2ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, df, n_mels=128):\n",
        "        self.df = df\n",
        "        self.n_mels = n_mels\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.labels = self.label_encoder.fit_transform(df['emotion'])  # Convert labels to numeric\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.df['path'].iloc[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Generate mel spectrogram\n",
        "        mel_spec = generate_mel_spectrogram(file_path, n_mels=self.n_mels)\n",
        "\n",
        "        # Convert to torch tensor\n",
        "        mel_spec = torch.tensor(mel_spec, dtype=torch.float32)\n",
        "\n",
        "        return mel_spec, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# Create dataset\n",
        "train_dataset = AudioDataset(train_df)\n",
        "test_dataset = AudioDataset(test_df)\n",
        "\n",
        "# DataLoader to batch and shuffle the data\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "bBGaL4luA5F0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "VVdvlZB8B9YQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ComplexTransformerModel(input_size=128, num_classes=6).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for mel_specs, labels in tqdm(train_loader):\n",
        "            mel_specs = mel_specs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(mel_specs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRX57HviBvaa",
        "outputId": "6744c0dc-880a-4162-b695-2f9eefc09db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "  6%|▋         | 12/187 [04:47<1:10:38, 24.22s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After training is completed\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/Crema/complex_transformer_model.pth\")\n",
        "print(\"Model saved successfully!\")\n"
      ],
      "metadata": {
        "id": "pX_rSSrbF1Ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for mel_specs, labels in test_loader:\n",
        "            mel_specs = mel_specs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(mel_specs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(model, test_loader)\n"
      ],
      "metadata": {
        "id": "ynC1KbU9B7YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Create dummy dataset for example purposes\n",
        "def generate_dummy_data(batch_size, seq_length, input_size, num_classes):\n",
        "    # Input tensor with random data\n",
        "    inputs = torch.randn(batch_size, seq_length, input_size)\n",
        "    # Random labels from 0 to num_classes-1\n",
        "    labels = torch.randint(0, num_classes, (batch_size,))\n",
        "    return inputs, labels\n",
        "\n",
        "# Training function\n",
        "def train_model(model, criterion, optimizer, num_epochs=10, batch_size=3200, seq_length=50, input_size=41, num_classes=6):\n",
        "    for epoch in range(num_epochs):\n",
        "        # Generate some dummy data\n",
        "        inputs, labels = generate_dummy_data(batch_size, seq_length, input_size, num_classes)\n",
        "\n",
        "        # Move data to the appropriate device (if using GPU)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print training stats\n",
        "        if (epoch + 1) % 2 == 0:\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = ComplexTransformerModel().to(device)\n",
        "criterion = nn.NLLLoss()  # Cross-entropy loss with log-softmax\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "train_model(model, criterion, optimizer, num_epochs=50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOdIzmFM-H74",
        "outputId": "b1b97b43-64c2-493d-f60e-e90687c69c48"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/50], Loss: 2.5093\n",
            "Epoch [4/50], Loss: 2.0127\n",
            "Epoch [6/50], Loss: 1.8258\n",
            "Epoch [8/50], Loss: 1.8528\n",
            "Epoch [10/50], Loss: 1.8169\n",
            "Epoch [12/50], Loss: 1.8139\n",
            "Epoch [14/50], Loss: 1.8195\n",
            "Epoch [16/50], Loss: 1.8160\n",
            "Epoch [18/50], Loss: 1.8068\n",
            "Epoch [20/50], Loss: 1.8042\n",
            "Epoch [22/50], Loss: 1.8083\n",
            "Epoch [24/50], Loss: 1.8106\n",
            "Epoch [26/50], Loss: 1.8052\n",
            "Epoch [28/50], Loss: 1.8048\n",
            "Epoch [30/50], Loss: 1.8048\n",
            "Epoch [32/50], Loss: 1.8039\n",
            "Epoch [34/50], Loss: 1.8034\n",
            "Epoch [36/50], Loss: 1.8054\n",
            "Epoch [38/50], Loss: 1.8042\n",
            "Epoch [40/50], Loss: 1.8037\n",
            "Epoch [42/50], Loss: 1.8053\n",
            "Epoch [44/50], Loss: 1.8042\n",
            "Epoch [46/50], Loss: 1.8018\n",
            "Epoch [48/50], Loss: 1.8012\n",
            "Epoch [50/50], Loss: 1.8010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'transformer_model.pth')\n",
        "print(\"Model saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwTgzlJr-Rzl",
        "outputId": "02da2689-300b-4f30-8562-2da03fba3a52"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model (ensure the model architecture is defined exactly the same way)\n",
        "loaded_model = ComplexTransformerModel().to(device)\n",
        "\n",
        "# Load the saved model weights\n",
        "loaded_model.load_state_dict(torch.load('transformer_model.pth'))\n",
        "loaded_model.eval()  # Set the model to evaluation mode\n",
        "print(\"Model loaded and ready for inference!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AugVWUEm-c8D",
        "outputId": "f5435bc5-cbf6-4886-adb6-f1f606ee8d2a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded and ready for inference!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-b68f3a39b46c>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model.load_state_dict(torch.load('transformer_model.pth'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference function\n",
        "def make_predictions(model, input_data):\n",
        "    # Ensure the model is in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # No need to compute gradients during inference\n",
        "    with torch.no_grad():\n",
        "        # Move input data to the device (GPU or CPU)\n",
        "        input_data = input_data.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(input_data)\n",
        "\n",
        "        # Get the predicted class (index with the maximum log-probability)\n",
        "        predictions = torch.argmax(output, dim=1) + 1  # Add 1 to shift range from 0-5 to 1-6\n",
        "\n",
        "        return predictions\n",
        "\n",
        "# Example new data (shape: batch_size, seq_length, input_size)\n",
        "new_data = torch.randn(8, 50, 41).to(device)  # Batch of 8 sequences of length 50 and input size 41\n",
        "\n",
        "# Make predictions with the loaded model\n",
        "predicted_labels = make_predictions(loaded_model, new_data)\n",
        "\n",
        "# Display the predictions\n",
        "print(\"Predicted labels:\", predicted_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUdETD-T-gNi",
        "outputId": "a4433d87-b86a-427b-cb9a-b02174f32363"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels: tensor([2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HjCbRlAt-mDY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}